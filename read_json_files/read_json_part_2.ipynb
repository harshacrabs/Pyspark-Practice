{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5180d23b-74b9-46f6-8b71-17120722ae76",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28426d9-c8ed-4e56-8a38-e887a1d3bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import flatten, collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6620442-7727-4281-affd-ac1d7fd05deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/11 18:48:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"read-json\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbd61d-9fb2-4fd5-bc41-92c6ad07129e",
   "metadata": {},
   "source": [
    "## Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dc0bdc-0905-44fd-8064-46c7290db15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(1, [[1,2], [3,4],  [5,6]]),\n",
    "     (2, [[7,8], [9,10], [11,12]])], [\"id\", \"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1a114b-9265-46f5-8c43-282c8b482596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                data|\n",
      "+---+--------------------+\n",
      "|  1|[[1, 2], [3, 4], ...|\n",
      "|  2|[[7, 8], [9, 10],...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6994ca-307f-4086-8d95-3f6fdf2c82fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------+\n",
      "|id |data                       |\n",
      "+---+---------------------------+\n",
      "|1  |[[1, 2], [3, 4], [5, 6]]   |\n",
      "|2  |[[7, 8], [9, 10], [11, 12]]|\n",
      "+---+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3386e-eaf0-4f85-a6b7-ccd80d231f8b",
   "metadata": {},
   "source": [
    "## Using collect_list() function to group by specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ada51f-02e3-4436-9d30-4fcb4eba6245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|data                                                   |\n",
      "+-------------------------------------------------------+\n",
      "|[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11, 12]]]|\n",
      "+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collect_df = df.select(collect_list(\"data\").alias(\"data\"))\n",
    "\n",
    "collect_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347665ec-5a0c-465a-bf8b-d1395bd919cf",
   "metadata": {},
   "source": [
    "## Merging the arrays elements using flatten() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1adc1bf1-498d-4399-9a9c-290104580814",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_df = collect_df.select(flatten(\"data\").alias(\"merged_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ee187f-0527-4c77-b238-165e9ce1d56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+\n",
      "|merged_data                                        |\n",
      "+---------------------------------------------------+\n",
      "|[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]]|\n",
      "+---------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatten_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c2505c4-8f5f-4053-95de-331efbe61f64",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "The flatten function only works with array columns.\n",
    "\n",
    "If you have a nested structure with multiple levels of arrays, you can use the explode() function\n",
    "to flatten the structure before using the flatten() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0adab2-ce74-4ce0-b133-5a413f93e567",
   "metadata": {},
   "source": [
    "## Using Flatten() function for Nested Array "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06aa57e-238f-40c5-8adb-211de27ec13b",
   "metadata": {},
   "source": [
    "## Create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aba87c1-fa3e-4126-a7b7-4e58b89d3cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------------+\n",
      "|id |data                                       |\n",
      "+---+-------------------------------------------+\n",
      "|1  |[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]       |\n",
      "|2  |[[[9, 10], [11, 12]], [[13, 14], [15, 16]]]|\n",
      "+---+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2 = spark.createDataFrame(\n",
    "    [(1, [[[1,2],[3,4]], [[5,6],[7,8]]]),\n",
    "     (2, [[[9,10], [11,12]], [[13,14], [15,16]]])], [\"id\", \"data\"])\n",
    "\n",
    "df_2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b97729-92fc-4ad6-9534-87ce3920fa67",
   "metadata": {},
   "source": [
    "## Explode the outermost array to flatten the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba3a5215-c508-42ca-81f4-1c301b1c2227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|          inner_data|\n",
      "+---+--------------------+\n",
      "|  1|    [[1, 2], [3, 4]]|\n",
      "|  1|    [[5, 6], [7, 8]]|\n",
      "|  2| [[9, 10], [11, 12]]|\n",
      "|  2|[[13, 14], [15, 16]]|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df = df_2.select(col(\"id\"), explode(\"data\").alias(\"inner_data\"))\n",
    "\n",
    "\n",
    "exploded_df.show()\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b13217-4677-44fe-ab0e-19aa4ed00664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, collect_list, flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a42ae2-78ba-472e-92a9-3f6114ff0b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|id |inner_data          |\n",
      "+---+--------------------+\n",
      "|1  |[[1, 2], [3, 4]]    |\n",
      "|1  |[[5, 6], [7, 8]]    |\n",
      "|2  |[[9, 10], [11, 12]] |\n",
      "|2  |[[13, 14], [15, 16]]|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df = df_2.select(col(\"id\"), explode(\"data\").alias(\"inner_data\"))\n",
    "\n",
    "\n",
    "exploded_df.show(truncate= False)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3ff251-0a4e-4b82-97a4-c2499bcb1317",
   "metadata": {},
   "source": [
    "## Use collect_list() to group all the inner arrays together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89710ccf-b1dc-4bae-afdc-7817b3c79a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------------+\n",
      "|id |merged_data                                |\n",
      "+---+-------------------------------------------+\n",
      "|1  |[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]       |\n",
      "|2  |[[[9, 10], [11, 12]], [[13, 14], [15, 16]]]|\n",
      "+---+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_df = exploded_df.groupby(\"id\").agg(collect_list(\"inner_data\").alias(\"merged_data\"))\n",
    "\n",
    "\n",
    "grouped_df.show(truncate=False)\n",
    "\n",
    "                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef798cbb-950a-49db-af8e-d10eac3919b6",
   "metadata": {},
   "source": [
    "## Use flatten() to merge all elements of the inner arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0060915-088a-4dc2-ac17-9fcc2808b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|final_data                             |\n",
      "+---------------------------------------+\n",
      "|[[1, 2], [3, 4], [5, 6], [7, 8]]       |\n",
      "|[[9, 10], [11, 12], [13, 14], [15, 16]]|\n",
      "+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flattened_df_2 = grouped_df.select(flatten(\"merged_data\").alias(\"final_data\"))\n",
    "\n",
    "flattened_df_2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376e1e1-25d7-4c2f-9b91-37a61463f550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
