{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7960904d-8bb2-4efb-8da8-79515bac38e6",
   "metadata": {},
   "source": [
    "## Import libraries and Create a SparkSession Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ff8ecb-8762-4bd7-aa6d-ae502cb253a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/07 15:26:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"read-csv-data\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.memory\", \"512m\")\n",
    "         .getOrCreate())\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"Error\")\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc591e-26b2-4402-9973-d42cc94bb91a",
   "metadata": {},
   "source": [
    "## Reading the csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f5006b-60eb-4a0b-bd5b-ddd7d651cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\",\"true\")\n",
    "      .load(\"../../data/netflix_titles.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd56a0-f838-4f08-8407-c01e30c3ff3c",
   "metadata": {},
   "source": [
    "## Display sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d334ee-f81b-4b84-91f7-c0e3faa4e45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|      country|        date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|Kirsten Johnson|                null|United States|September 25, 2021|        2020| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|           null|Ama Qamata, Khosi...| South Africa|September 24, 2021|        2021| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|Julien Leclercq|Sami Bouajila, Tr...|         null|September 24, 2021|        2021| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "|     s4|TV Show|Jailbirds New Orl...|           null|                null|         null|September 24, 2021|        2021| TV-MA| 1 Season|Docuseries, Reali...|Feuds, flirtation...|\n",
      "|     s5|TV Show|        Kota Factory|           null|Mayur More, Jiten...|        India|September 24, 2021|        2021| TV-MA|2 Seasons|International TV ...|In a city of coac...|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19410af7-b029-438b-93d9-807f7a589368",
   "metadata": {},
   "source": [
    "## Check the data types of the columns (Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0259c4b7-ff5f-46e7-b9e2-ac4bae0aa347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "238c6ed3-7a26-459f-ad9a-20fc6650f345",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "We could see that some of the columns are not of the correct datatype.(date_added, release_year, rating, duration etcc.)\n",
    "\n",
    "We can define our own schema while reading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c6584-1da7-4acd-8dd7-5577da009b8d",
   "metadata": {},
   "source": [
    "## Read the csv data with an explicit schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6e8d0e-95b9-4865-bb5a-ace0e3795198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DateType\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "751a9cba-b40f-4f76-9577-289c754b1749",
   "metadata": {},
   "source": [
    "schema = StructType(\n",
    "    [StructField(\"showid\", StringType(), True), #True means the column is nullable or not\n",
    "     StructField(\"type\", StringType(), True),\n",
    "     StructField(\"title\", StringType(), True)\n",
    "     .....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec306b5-8a39-48fe-b0c8-0e2ddbbf9ae0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### I want to avoid this manual typing of each column.So, I create a dictionary and edit it\n",
    "\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130cf789-d499-4184-b1fd-ac8a24e83faf",
   "metadata": {},
   "source": [
    "### First I create a dictionary from the column names and datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40d9954e-93ee-4f3b-9530-a30d2229e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'show_id': StringType(),\n",
       " 'type': StringType(),\n",
       " 'title': StringType(),\n",
       " 'director': StringType(),\n",
       " 'cast': StringType(),\n",
       " 'country': StringType(),\n",
       " 'date_added': StringType(),\n",
       " 'release_year': StringType(),\n",
       " 'rating': StringType(),\n",
       " 'duration': StringType(),\n",
       " 'listed_in': StringType(),\n",
       " 'description': StringType()}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dict = {field.name : field.dataType for field in df.schema.fields}\n",
    "schema_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3722ac9-18ac-47c7-a9a5-a422f23d4297",
   "metadata": {},
   "source": [
    "### I modify the dictionary with my required datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2411f570-c23c-4478-9804-651a90f5e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifications = {\n",
    "    'date_added': DateType(),\n",
    "    'release_year': DateType()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f210a63-47f6-4716-b57d-2f6395df86a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'show_id': StringType(),\n",
       " 'type': StringType(),\n",
       " 'title': StringType(),\n",
       " 'director': StringType(),\n",
       " 'cast': StringType(),\n",
       " 'country': StringType(),\n",
       " 'date_added': DateType(),\n",
       " 'release_year': DateType(),\n",
       " 'rating': StringType(),\n",
       " 'duration': StringType(),\n",
       " 'listed_in': StringType(),\n",
       " 'description': StringType()}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dict.update(modifications)\n",
    "\n",
    "schema_dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31386743-1c70-4892-8196-ae8212f6f3a7",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "\n",
    "1.\tDo not assign .update() to a variable → .update() modifies schema_dict in place.\n",
    "2.\tUse .update() directly → The dictionary will be modified without needing reassignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222811f0-4e5b-4370-b312-51e71b650af9",
   "metadata": {},
   "source": [
    "### Then I create the schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "506c555f-c041-4bcf-85f7-73e46e4ca55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fb78dee-5fa3-4e38-bd2f-0b010a496142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('show_id', StringType(), True), StructField('type', StringType(), True), StructField('title', StringType(), True), StructField('director', StringType(), True), StructField('cast', StringType(), True), StructField('country', StringType(), True), StructField('date_added', DateType(), True), StructField('release_year', DateType(), True), StructField('rating', StringType(), True), StructField('duration', StringType(), True), StructField('listed_in', StringType(), True), StructField('description', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField(name, dtype, True)  for name, dtype in schema_dict.items()])\n",
    "\n",
    "pprint(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f51a1-29c0-4ce0-a5e0-5a91b7f65304",
   "metadata": {},
   "source": [
    "## Read csv data with explicitly defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08c6855d-7882-4e59-98a9-15e3f25fcc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv')\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .schema(schema)\\\n",
    "                .load(\"../../data/netflix_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3207d0ec-c6f3-4c4d-930d-6b99fd8ac664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: date (nullable = true)\n",
      " |-- release_year: date (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9809349f-0779-41fe-a88f-4c8c4fed7e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|      country|date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|Kirsten Johnson|                null|United States|      null|  2020-01-01| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|           null|Ama Qamata, Khosi...| South Africa|      null|  2021-01-01| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|Julien Leclercq|Sami Bouajila, Tr...|         null|      null|  2021-01-01| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "|     s4|TV Show|Jailbirds New Orl...|           null|                null|         null|      null|  2021-01-01| TV-MA| 1 Season|Docuseries, Reali...|Feuds, flirtation...|\n",
      "|     s5|TV Show|        Kota Factory|           null|Mayur More, Jiten...|        India|      null|  2021-01-01| TV-MA|2 Seasons|International TV ...|In a city of coac...|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a2515d-fa29-4a16-98e7-f35be8d7be7a",
   "metadata": {},
   "source": [
    "## Reading csv when delimiter value is present within the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66222bf4-ab39-44dd-8cf3-09cf33ccb7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .option(\"nullValue\", \"null\")\\\n",
    "                .option(\"escapeQuotes\", \"true\")\\\n",
    "                .schema(schema)\\\n",
    "                .load(\"../../data/netflix_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf7c5c0e-8d55-4bdd-b7a6-f28f285c95e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|      country|date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|Kirsten Johnson|                null|United States|      null|  2020-01-01| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|           null|Ama Qamata, Khosi...| South Africa|      null|  2021-01-01| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|Julien Leclercq|Sami Bouajila, Tr...|         null|      null|  2021-01-01| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "|     s4|TV Show|Jailbirds New Orl...|           null|                null|         null|      null|  2021-01-01| TV-MA| 1 Season|Docuseries, Reali...|Feuds, flirtation...|\n",
      "|     s5|TV Show|        Kota Factory|           null|Mayur More, Jiten...|        India|      null|  2021-01-01| TV-MA|2 Seasons|International TV ...|In a city of coac...|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1245b6e0-30c7-442d-83e0-42ebc2dbc556",
   "metadata": {},
   "source": [
    "1. .option(\"nullValue\", \"null\")\n",
    "\n",
    "This option treats a specific string as NULL when loading the CSV.\n",
    "\n",
    "Explanation\n",
    "\t•\tIf the CSV contains \"null\", Spark will replace it with None (NULL in DataFrame).\n",
    "\t•\tIf not specified, \"null\" will be treated as a regular string instead of an actual NULL.\n",
    "\n",
    "\n",
    "✅ Without .option(\"nullValue\", \"null\"), “null” would appear as a string instead of NULL."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e01e32e-b74c-4718-abf2-8d6c3f1dac10",
   "metadata": {},
   "source": [
    "2. .option(\"escapeQuotes\", \"true\")\n",
    "\n",
    "This option ensures proper handling of double quotes (\") inside quoted strings.\n",
    "\n",
    "Why is this needed?\n",
    "\n",
    "Sometimes, CSV fields are enclosed in quotes, and those fields might contain additional quotes inside. Without escapeQuotes, Spark may misinterpret them.\n",
    "\n",
    "Example\n",
    "\n",
    "show_id,type,title,description\n",
    "s1,Movie,\"Inception\",\"A mind-bending thriller \"\"dream\"\" experience\"\n",
    "s2,Show,\"Breaking Bad\",\"A chemistry teacher turns to \"\"cooking\"\"\"\n",
    "\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .option(\"escapeQuotes\", \"true\")\\  # Handles escaped quotes\n",
    "                .load(\"netflix_titles.csv\")\n",
    "\n",
    "df.show(truncate=False)\n",
    "\n",
    "+--------+------+--------------+-------------------------------------------------+\n",
    "| show_id| type | title        | description                                     |\n",
    "+--------+------+--------------+-------------------------------------------------+\n",
    "| s1     | Movie| Inception    | A mind-bending thriller \"dream\" experience     |\n",
    "| s2     | Show | Breaking Bad | A chemistry teacher turns to \"cooking\"         |\n",
    "+--------+------+--------------+-------------------------------------------------+\n",
    "\n",
    "✅ Without .option(\"escapeQuotes\", \"true\"), the presence of extra quotes (\"\"dream\"\") would break parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d6309-5aca-4fd1-867f-36b984e40599",
   "metadata": {},
   "source": [
    "## Different Dateformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "187300e8-123e-4c27-bae4-180272efa454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .option(\"nullValue\", \"null\")\\\n",
    "                .option(\"dateFormat\", \"LLLL d,y\")\\\n",
    "                .option(\"escapeQuotes\", \"true\")\\\n",
    "                .schema(schema)\\\n",
    "                .load(\"../../data/netflix_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3a1778e-40e2-41c4-bda6-bd3efdee8a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|      country|date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|Kirsten Johnson|                null|United States|      null|        null| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|           null|Ama Qamata, Khosi...| South Africa|      null|        null| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|Julien Leclercq|Sami Bouajila, Tr...|         null|      null|        null| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "|     s4|TV Show|Jailbirds New Orl...|           null|                null|         null|      null|        null| TV-MA| 1 Season|Docuseries, Reali...|Feuds, flirtation...|\n",
      "|     s5|TV Show|        Kota Factory|           null|Mayur More, Jiten...|        India|      null|        null| TV-MA|2 Seasons|International TV ...|In a city of coac...|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773905e-904b-4004-a250-d2aae9589d78",
   "metadata": {},
   "source": [
    "PySpark follows Java’s SimpleDateFormat pattern, so you can use various date format patterns:\n",
    "\n",
    "| Format                             | Example Input                   | Pattern                     |\n",
    "|------------------------------------|--------------------------------|-----------------------------|\n",
    "| Full Month Name, Day, Year        | December 25, 2020             | `\"LLLL d,y\"`                |\n",
    "| Short Month Name, Day, Year       | Dec 25, 2020                  | `\"MMM d,y\"`                 |\n",
    "| Day-Month-Year                    | 25-12-2020                    | `\"dd-MM-yyyy\"`              |\n",
    "| Year-Month-Day (ISO Format)       | 2020-12-25                    | `\"yyyy-MM-dd\"`              |\n",
    "| Month/Day/Year                    | 12/25/2020                    | `\"MM/dd/yyyy\"`              |\n",
    "| Day/Month/Year                    | 25/12/2020                    | `\"dd/MM/yyyy\"`              |\n",
    "| Year-Month-Day Hour:Minute        | 2020-12-25 14:30              | `\"yyyy-MM-dd HH:mm\"`        |\n",
    "| Full Date & Time                  | Fri, 25 Dec 2020 14:30:00 GMT | `\"EEE, d MMM yyyy HH:mm:ss z\"` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2edbc8-5212-433d-8e5a-1009dedd2b19",
   "metadata": {},
   "source": [
    "## Infer Schema by Pyspark"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49eb4a33-67a0-4dc0-bf05-f85b35bba956",
   "metadata": {},
   "source": [
    ".option(\"inferSchema\", \"true\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2917602-5bb2-42e1-9098-4458de336f31",
   "metadata": {},
   "source": [
    "## Handling missing data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5436a29-5474-4441-a28e-fe2595def69a",
   "metadata": {},
   "source": [
    ".option(\"nullValue\", \"NA\") # for a file where \"NA\" represents null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1349d-fe39-420f-9018-e7958abc0a36",
   "metadata": {},
   "source": [
    "## Handling malformed data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9996026e-af26-41b8-a8a6-bc6d680f632d",
   "metadata": {},
   "source": [
    ".option(\"mode\", \"PERMISSIVE\") # to ignore parsing errors and continue parsing the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ed888-6a9d-4145-b756-204f10b7c3e8",
   "metadata": {},
   "source": [
    "## Working with large CSV files"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2ff5d0a-42c7-4ea3-92f3-28d2d646037d",
   "metadata": {},
   "source": [
    ".option(\"maxColumns\", 5000)\n",
    "\n",
    "Use Case\n",
    "\t•\tIf a CSV file has an extremely high number of columns (e.g., 1000+), this option prevents memory overload.\n",
    "\t•\tDefault: 20480 columns (20,480).\n",
    "\t•\tIf the CSV has more columns than the set limit, Spark throws an error.\n",
    "\n",
    "✅ If the CSV has 10,000 columns but maxColumns=5000, Spark throws an error.\n",
    "\n",
    "\n",
    ".option(\"maxCharsPerColumn\", value)\n",
    "\n",
    "This option sets the maximum number of characters allowed in a single column entry.\n",
    "\n",
    "Use Case\n",
    "\t•\tUseful when dealing with text-heavy datasets, such as:\n",
    "\t•\tProduct descriptions\n",
    "\t•\tLarge JSON fields inside CSV\n",
    "\t•\tLong article content\n",
    "\t•\tDefault: 100000 characters (100K).\n",
    "\n",
    "\t•\tDefault: 100000 characters (100K).\n",
    "\t•\tIf a field exceeds the limit, Spark truncates the value or throws an error.\n",
    "\n",
    " ✅ If a column contains text longer than maxCharsPerColumn=50000, Spark truncates it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d92a3-8b1f-412b-a299-e018fb2a56c8",
   "metadata": {},
   "source": [
    "## Read large CSV files as a stream"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9afd6d7-9fd6-4da5-afe8-39a5cd0d03bb",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"StreamingExample\").getOrCreate()\n",
    "\n",
    "# Read a streaming CSV file\n",
    "df = spark.readStream.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"maxFilesPerTrigger\", 1)\\  # Processes one file at a time\n",
    "    .schema(\"id INT, name STRING, age INT\")\\  # Define schema for structured streaming\n",
    "    .load(\"path/to/streaming_folder\")  # Directory where new files appear\n",
    "\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
